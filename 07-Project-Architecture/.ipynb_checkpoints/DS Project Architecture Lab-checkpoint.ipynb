{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nose.tools import *\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Write your imports here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "525f2882f2b6e191652899e33517abb4",
     "grade": false,
     "grade_id": "cell-1b7f77949e7a3450",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Data Science Project Architecture Lab\n",
    "## End-to-end project: demonstrating the power of OSEMN. Transition towards modelling. Machine learning basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "On 15 April 1912, the Titanic sank after colliding with an iceberg, killing more than two thirds of the crew and passengers. The dataset provided for you in the `data/` folder contains information about the passengers onboard and which of them survived.\n",
    "\n",
    "The goal of this lab is to explore the data, prepare it for modelling, and perform a (kind of) simple classification. We'll also explore some basics of practical machine learning such as data preparation, testing and training sets, and model evaluation.\n",
    "\n",
    "The original dataset is located [here](https://www.kaggle.com/c/titanic/data). You can read the page for more information about the data and variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1. Read the dataset (1 point)\n",
    "Read the dataset in the `data/titanic.csv` file into the `titanic_data` variable. Here's a short description of what each column means:\n",
    "* PassengerId - a unique number identifying each passenger\n",
    "* Survived - indicator variable: 1 if the passenger survived, 0 otherwise\n",
    "* Pclass - passenger ticket class (1, 2 or 3). This can be used as an indicator of wealth\n",
    "* Name\n",
    "* Sex\n",
    "* Age\n",
    "* SibSp - number of siblings / spouses aboard the Titanic\n",
    "* Parch - number of parents / children aboard the Titanic\n",
    "* Ticket - ticket number\n",
    "* Fare - passenger fare (price)\n",
    "* Cabin - cabin number\n",
    "* Embarked - port of embarkation: C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "\n",
    "**Notes on family relationships:**\n",
    "* Sibling = brother, sister, stepbrother, stepsister\n",
    "* Spouse = husband, wife (mistresses and fiancés were ignored)\n",
    "* Parent = mother, father\n",
    "* Child = daughter, son, stepdaughter, stepson. Some children travelled only with a nanny, therefore Parch = 0 for them.\n",
    "\n",
    "Set the index column to be \"PassengerId\". Rename \"Pclass\" to \"Class\" and \"Parch\" to \"ParCh\". Other than that, the column names aren't too bad (although not Pythonic enough). Don't rename them.\n",
    "\n",
    "Also, change the \"Embarked\" column to include the full names of the ports (see the column descriptions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9f7e61b1a2b4b2484ae37f526f0a863f",
     "grade": false,
     "grade_id": "cell-8d05536388210811",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Class</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>ParCh</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>Cherbourg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queenstown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cherbourg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Saundercock, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5. 2151</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Mr. Anders Johan</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vestrom, Miss. Hulda Amanda Adolfina</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350406</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Hewlett, Mrs. (Mary D Kingcome)</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248706</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Master. Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queenstown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Williams, Mr. Charles Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244373</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Planke, Mrs. Julius (Emelia Maria Vande...</td>\n",
       "      <td>female</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>345763</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Masselmani, Mrs. Fatima</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2649</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cherbourg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Fynney, Mr. Joseph J</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239865</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Beesley, Mr. Lawrence</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248698</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>D56</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>McGowan, Miss. Anna \"Annie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330923</td>\n",
       "      <td>8.0292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queenstown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sloper, Mr. William Thompson</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113788</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>A6</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Miss. Torborg Danira</td>\n",
       "      <td>female</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347077</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Emir, Mr. Farred Chehab</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2631</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cherbourg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Mr. Charles Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>O'Dwyer, Miss. Ellen \"Nellie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330959</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queenstown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Todoroff, Mr. Lalio</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349216</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Giles, Mr. Frederick Edward</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28134</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Swift, Mrs. Frederick Joel (Margaret Welles Ba...</td>\n",
       "      <td>female</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17466</td>\n",
       "      <td>25.9292</td>\n",
       "      <td>D17</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Miss. Dorothy Edith \"Dolly\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Gill, Mr. John William</td>\n",
       "      <td>male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>233866</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Bystrom, Mrs. (Karolina)</td>\n",
       "      <td>female</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>236852</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Duran y More, Miss. Asuncion</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SC/PARIS 2149</td>\n",
       "      <td>13.8583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cherbourg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Roebling, Mr. Washington Augustus II</td>\n",
       "      <td>male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17590</td>\n",
       "      <td>50.4958</td>\n",
       "      <td>A24</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>van Melkebeke, Mr. Philemon</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345777</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Master. Harold Theodor</td>\n",
       "      <td>male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Balkic, Mr. Cerin</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349248</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Beckwith, Mrs. Richard Leonard (Sallie Monypeny)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11751</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>D35</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Carlsson, Mr. Frans Olof</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>695</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>B51 B53 B55</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Cruyssen, Mr. Victor</td>\n",
       "      <td>male</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345765</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Abelson, Mrs. Samuel (Hannah Wizosky)</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>P/PP 3381</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cherbourg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Najib, Miss. Adele Kiamie \"Jane\"</td>\n",
       "      <td>female</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2667</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cherbourg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Gustafsson, Mr. Alfred Ossian</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7534</td>\n",
       "      <td>9.8458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Petroff, Mr. Nedelio</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349212</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Laleff, Mr. Kristo</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349217</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)</td>\n",
       "      <td>female</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11767</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>C50</td>\n",
       "      <td>Cherbourg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Shelley, Mrs. William (Imanita Parrish Hall)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>230433</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Markun, Mr. Johann</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349257</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dahlberg, Miss. Gerda Ulrika</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7552</td>\n",
       "      <td>10.5167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Banfield, Mr. Frederick James</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A./SOTON 34068</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sutehall, Mr. Henry Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/OQ 392076</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Mrs. William (Margaret Norton)</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queenstown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>Cherbourg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queenstown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Class  \\\n",
       "PassengerId                    \n",
       "1                   0      3   \n",
       "2                   1      1   \n",
       "3                   1      3   \n",
       "4                   1      1   \n",
       "5                   0      3   \n",
       "6                   0      3   \n",
       "7                   0      1   \n",
       "8                   0      3   \n",
       "9                   1      3   \n",
       "10                  1      2   \n",
       "11                  1      3   \n",
       "12                  1      1   \n",
       "13                  0      3   \n",
       "14                  0      3   \n",
       "15                  0      3   \n",
       "16                  1      2   \n",
       "17                  0      3   \n",
       "18                  1      2   \n",
       "19                  0      3   \n",
       "20                  1      3   \n",
       "21                  0      2   \n",
       "22                  1      2   \n",
       "23                  1      3   \n",
       "24                  1      1   \n",
       "25                  0      3   \n",
       "26                  1      3   \n",
       "27                  0      3   \n",
       "28                  0      1   \n",
       "29                  1      3   \n",
       "30                  0      3   \n",
       "...               ...    ...   \n",
       "862                 0      2   \n",
       "863                 1      1   \n",
       "864                 0      3   \n",
       "865                 0      2   \n",
       "866                 1      2   \n",
       "867                 1      2   \n",
       "868                 0      1   \n",
       "869                 0      3   \n",
       "870                 1      3   \n",
       "871                 0      3   \n",
       "872                 1      1   \n",
       "873                 0      1   \n",
       "874                 0      3   \n",
       "875                 1      2   \n",
       "876                 1      3   \n",
       "877                 0      3   \n",
       "878                 0      3   \n",
       "879                 0      3   \n",
       "880                 1      1   \n",
       "881                 1      2   \n",
       "882                 0      3   \n",
       "883                 0      3   \n",
       "884                 0      2   \n",
       "885                 0      3   \n",
       "886                 0      3   \n",
       "887                 0      2   \n",
       "888                 1      1   \n",
       "889                 0      3   \n",
       "890                 1      1   \n",
       "891                 0      3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "6                                             Moran, Mr. James    male   NaN   \n",
       "7                                      McCarthy, Mr. Timothy J    male  54.0   \n",
       "8                               Palsson, Master. Gosta Leonard    male   2.0   \n",
       "9            Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0   \n",
       "10                         Nasser, Mrs. Nicholas (Adele Achem)  female  14.0   \n",
       "11                             Sandstrom, Miss. Marguerite Rut  female   4.0   \n",
       "12                                    Bonnell, Miss. Elizabeth  female  58.0   \n",
       "13                              Saundercock, Mr. William Henry    male  20.0   \n",
       "14                                 Andersson, Mr. Anders Johan    male  39.0   \n",
       "15                        Vestrom, Miss. Hulda Amanda Adolfina  female  14.0   \n",
       "16                            Hewlett, Mrs. (Mary D Kingcome)   female  55.0   \n",
       "17                                        Rice, Master. Eugene    male   2.0   \n",
       "18                                Williams, Mr. Charles Eugene    male   NaN   \n",
       "19           Vander Planke, Mrs. Julius (Emelia Maria Vande...  female  31.0   \n",
       "20                                     Masselmani, Mrs. Fatima  female   NaN   \n",
       "21                                        Fynney, Mr. Joseph J    male  35.0   \n",
       "22                                       Beesley, Mr. Lawrence    male  34.0   \n",
       "23                                 McGowan, Miss. Anna \"Annie\"  female  15.0   \n",
       "24                                Sloper, Mr. William Thompson    male  28.0   \n",
       "25                               Palsson, Miss. Torborg Danira  female   8.0   \n",
       "26           Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...  female  38.0   \n",
       "27                                     Emir, Mr. Farred Chehab    male   NaN   \n",
       "28                              Fortune, Mr. Charles Alexander    male  19.0   \n",
       "29                               O'Dwyer, Miss. Ellen \"Nellie\"  female   NaN   \n",
       "30                                         Todoroff, Mr. Lalio    male   NaN   \n",
       "...                                                        ...     ...   ...   \n",
       "862                                Giles, Mr. Frederick Edward    male  21.0   \n",
       "863          Swift, Mrs. Frederick Joel (Margaret Welles Ba...  female  48.0   \n",
       "864                          Sage, Miss. Dorothy Edith \"Dolly\"  female   NaN   \n",
       "865                                     Gill, Mr. John William    male  24.0   \n",
       "866                                   Bystrom, Mrs. (Karolina)  female  42.0   \n",
       "867                               Duran y More, Miss. Asuncion  female  27.0   \n",
       "868                       Roebling, Mr. Washington Augustus II    male  31.0   \n",
       "869                                van Melkebeke, Mr. Philemon    male   NaN   \n",
       "870                            Johnson, Master. Harold Theodor    male   4.0   \n",
       "871                                          Balkic, Mr. Cerin    male  26.0   \n",
       "872           Beckwith, Mrs. Richard Leonard (Sallie Monypeny)  female  47.0   \n",
       "873                                   Carlsson, Mr. Frans Olof    male  33.0   \n",
       "874                                Vander Cruyssen, Mr. Victor    male  47.0   \n",
       "875                      Abelson, Mrs. Samuel (Hannah Wizosky)  female  28.0   \n",
       "876                           Najib, Miss. Adele Kiamie \"Jane\"  female  15.0   \n",
       "877                              Gustafsson, Mr. Alfred Ossian    male  20.0   \n",
       "878                                       Petroff, Mr. Nedelio    male  19.0   \n",
       "879                                         Laleff, Mr. Kristo    male   NaN   \n",
       "880              Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)  female  56.0   \n",
       "881               Shelley, Mrs. William (Imanita Parrish Hall)  female  25.0   \n",
       "882                                         Markun, Mr. Johann    male  33.0   \n",
       "883                               Dahlberg, Miss. Gerda Ulrika  female  22.0   \n",
       "884                              Banfield, Mr. Frederick James    male  28.0   \n",
       "885                                     Sutehall, Mr. Henry Jr    male  25.0   \n",
       "886                       Rice, Mrs. William (Margaret Norton)  female  39.0   \n",
       "887                                      Montvila, Rev. Juozas    male  27.0   \n",
       "888                               Graham, Miss. Margaret Edith  female  19.0   \n",
       "889                   Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN   \n",
       "890                                      Behr, Mr. Karl Howell    male  26.0   \n",
       "891                                        Dooley, Mr. Patrick    male  32.0   \n",
       "\n",
       "             SibSp  ParCh            Ticket      Fare        Cabin  \\\n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171    7.2500          NaN   \n",
       "2                1      0          PC 17599   71.2833          C85   \n",
       "3                0      0  STON/O2. 3101282    7.9250          NaN   \n",
       "4                1      0            113803   53.1000         C123   \n",
       "5                0      0            373450    8.0500          NaN   \n",
       "6                0      0            330877    8.4583          NaN   \n",
       "7                0      0             17463   51.8625          E46   \n",
       "8                3      1            349909   21.0750          NaN   \n",
       "9                0      2            347742   11.1333          NaN   \n",
       "10               1      0            237736   30.0708          NaN   \n",
       "11               1      1           PP 9549   16.7000           G6   \n",
       "12               0      0            113783   26.5500         C103   \n",
       "13               0      0         A/5. 2151    8.0500          NaN   \n",
       "14               1      5            347082   31.2750          NaN   \n",
       "15               0      0            350406    7.8542          NaN   \n",
       "16               0      0            248706   16.0000          NaN   \n",
       "17               4      1            382652   29.1250          NaN   \n",
       "18               0      0            244373   13.0000          NaN   \n",
       "19               1      0            345763   18.0000          NaN   \n",
       "20               0      0              2649    7.2250          NaN   \n",
       "21               0      0            239865   26.0000          NaN   \n",
       "22               0      0            248698   13.0000          D56   \n",
       "23               0      0            330923    8.0292          NaN   \n",
       "24               0      0            113788   35.5000           A6   \n",
       "25               3      1            349909   21.0750          NaN   \n",
       "26               1      5            347077   31.3875          NaN   \n",
       "27               0      0              2631    7.2250          NaN   \n",
       "28               3      2             19950  263.0000  C23 C25 C27   \n",
       "29               0      0            330959    7.8792          NaN   \n",
       "30               0      0            349216    7.8958          NaN   \n",
       "...            ...    ...               ...       ...          ...   \n",
       "862              1      0             28134   11.5000          NaN   \n",
       "863              0      0             17466   25.9292          D17   \n",
       "864              8      2          CA. 2343   69.5500          NaN   \n",
       "865              0      0            233866   13.0000          NaN   \n",
       "866              0      0            236852   13.0000          NaN   \n",
       "867              1      0     SC/PARIS 2149   13.8583          NaN   \n",
       "868              0      0          PC 17590   50.4958          A24   \n",
       "869              0      0            345777    9.5000          NaN   \n",
       "870              1      1            347742   11.1333          NaN   \n",
       "871              0      0            349248    7.8958          NaN   \n",
       "872              1      1             11751   52.5542          D35   \n",
       "873              0      0               695    5.0000  B51 B53 B55   \n",
       "874              0      0            345765    9.0000          NaN   \n",
       "875              1      0         P/PP 3381   24.0000          NaN   \n",
       "876              0      0              2667    7.2250          NaN   \n",
       "877              0      0              7534    9.8458          NaN   \n",
       "878              0      0            349212    7.8958          NaN   \n",
       "879              0      0            349217    7.8958          NaN   \n",
       "880              0      1             11767   83.1583          C50   \n",
       "881              0      1            230433   26.0000          NaN   \n",
       "882              0      0            349257    7.8958          NaN   \n",
       "883              0      0              7552   10.5167          NaN   \n",
       "884              0      0  C.A./SOTON 34068   10.5000          NaN   \n",
       "885              0      0   SOTON/OQ 392076    7.0500          NaN   \n",
       "886              0      5            382652   29.1250          NaN   \n",
       "887              0      0            211536   13.0000          NaN   \n",
       "888              0      0            112053   30.0000          B42   \n",
       "889              1      2        W./C. 6607   23.4500          NaN   \n",
       "890              0      0            111369   30.0000         C148   \n",
       "891              0      0            370376    7.7500          NaN   \n",
       "\n",
       "                Embarked  \n",
       "PassengerId               \n",
       "1            Southampton  \n",
       "2              Cherbourg  \n",
       "3            Southampton  \n",
       "4            Southampton  \n",
       "5            Southampton  \n",
       "6             Queenstown  \n",
       "7            Southampton  \n",
       "8            Southampton  \n",
       "9            Southampton  \n",
       "10             Cherbourg  \n",
       "11           Southampton  \n",
       "12           Southampton  \n",
       "13           Southampton  \n",
       "14           Southampton  \n",
       "15           Southampton  \n",
       "16           Southampton  \n",
       "17            Queenstown  \n",
       "18           Southampton  \n",
       "19           Southampton  \n",
       "20             Cherbourg  \n",
       "21           Southampton  \n",
       "22           Southampton  \n",
       "23            Queenstown  \n",
       "24           Southampton  \n",
       "25           Southampton  \n",
       "26           Southampton  \n",
       "27             Cherbourg  \n",
       "28           Southampton  \n",
       "29            Queenstown  \n",
       "30           Southampton  \n",
       "...                  ...  \n",
       "862          Southampton  \n",
       "863          Southampton  \n",
       "864          Southampton  \n",
       "865          Southampton  \n",
       "866          Southampton  \n",
       "867            Cherbourg  \n",
       "868          Southampton  \n",
       "869          Southampton  \n",
       "870          Southampton  \n",
       "871          Southampton  \n",
       "872          Southampton  \n",
       "873          Southampton  \n",
       "874          Southampton  \n",
       "875            Cherbourg  \n",
       "876            Cherbourg  \n",
       "877          Southampton  \n",
       "878          Southampton  \n",
       "879          Southampton  \n",
       "880            Cherbourg  \n",
       "881          Southampton  \n",
       "882          Southampton  \n",
       "883          Southampton  \n",
       "884          Southampton  \n",
       "885          Southampton  \n",
       "886           Queenstown  \n",
       "887          Southampton  \n",
       "888          Southampton  \n",
       "889          Southampton  \n",
       "890            Cherbourg  \n",
       "891           Queenstown  \n",
       "\n",
       "[891 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data = pd.read_csv(\"data/titanic.csv\",index_col=\"PassengerId\")\n",
    "titanic_data.columns = [\"Survived\",\"Class\",\"Name\",\"Sex\",\"Age\",\"SibSp\",\"ParCh\",\"Ticket\",\"Fare\",\"Cabin\",\"Embarked\"]\n",
    "embarked = titanic_data.Embarked.replace(to_replace={'S':\"Southampton\",'C':\"Cherbourg\",'Q':\"Queenstown\"})\n",
    "titanic_data.drop(\"Embarked\",axis = 1)\n",
    "titanic_data[\"Embarked\"] = embarked\n",
    "titanic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f2593c9c3a6fb7e30c59ff555f621201",
     "grade": true,
     "grade_id": "cell-eeefe71b639dffe8",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_not_none(titanic_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2. Inspect and fill missing data (1 point)\n",
    "See how many records are missing for each column. You can just execute the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 11 columns):\n",
      "Survived    891 non-null int64\n",
      "Class       891 non-null int64\n",
      "Name        891 non-null object\n",
      "Sex         891 non-null object\n",
      "Age         714 non-null float64\n",
      "SibSp       891 non-null int64\n",
      "ParCh       891 non-null int64\n",
      "Ticket      891 non-null object\n",
      "Fare        891 non-null float64\n",
      "Cabin       204 non-null object\n",
      "Embarked    889 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 83.5+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that most of the data is there. We have some people with unknown ages and two people with unknown embarkation ports.\n",
    "\n",
    "For missing ages, there are three approaches. We can't say right now which will prove the most correct but we'll stick to one.\n",
    "* Remove people with unknown ages - not desirable, since they are many\n",
    "* Replace unknown ages with a \"centinel\" value, e.g. $-1$ - not desirable because this will introduce invalid data which may throw our models off \n",
    "* Replace unknown ages with the column mean\n",
    "\n",
    "We'll stick with the third approach. Replace the `NaN` values in the `Age` column with the column mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "03704d4a37ab89e1ae20c7b07a8dca02",
     "grade": false,
     "grade_id": "cell-cda0e1f62b8fa17e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect missing embarkation ports. Store the passengers with unknown embarkation ports in the provided variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "10acfa449e026fa555c709469ad0f7eb",
     "grade": false,
     "grade_id": "cell-c81adf03dbc34dba",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "passengers_with_unknown_embarkation_ports = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "passengers_with_unknown_embarkation_ports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there are two such passengers with the same ticket. We can check there are no other passengers with the same ticket number. We have no idea what to do but we might just replace them with the most common embarkation port.\n",
    "\n",
    "Find out which port was the most common. Replace the two NaN values in the dataset with this port."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "741792adac4959231666ba263fe30166",
     "grade": false,
     "grade_id": "cell-bd2f821dd9cb5fc9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "most_common_port = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "85b021c52a9b2d0f0daa3f112e9f00ff",
     "grade": true,
     "grade_id": "cell-50f02a8a39bf9d82",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Tests for all operations\n",
    "assert_false(titanic_data.Age.isnull().any())\n",
    "\n",
    "assert_is_not_none(passengers_with_unknown_embarkation_ports)\n",
    "assert_is_not_none(most_common_port)\n",
    "assert_false(titanic_data.Embarked.isnull().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3. Remove unnecessary columns (1 point)\n",
    "The `Cabin` column contains too many missing values. Probably the best we can do with it is remove it. Also, the names and ticket numbers might be useful in another analysis, but not in this case. We're interested in which passengers survived and we have no reason to think that their names might be related to their survival rate. Also, the ticket numbers are somewhat random.\n",
    "\n",
    "**Note:** It might be interesting to extract the titles of the passengers (e.g. \"Mr.\", \"Miss\", \"Dr.\", etc.) and see whether it correlates to survival rate (e.g. people with higher social status might be more likely to get a boat and survive). But let's not focus on this right now. The class and ticket fare are good enough to indicate social status / wealth.\n",
    "\n",
    "Remove the `Cabin`, `Name`, and `Ticket` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "10490df105b93dffee0e19d79e3bbe1a",
     "grade": false,
     "grade_id": "cell-4d96142a29f5f032",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a6743518d8895b2a77bed489ef09cf7f",
     "grade": true,
     "grade_id": "cell-ce236d7fee7f5854",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(titanic_data.shape, (891, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4. Explore the data: single variables (1 point)\n",
    "Let's start with visualizing single variables. \n",
    "\n",
    "Try plotting a histogram of all ages with 20 bins. You'll see a kind of unusual peak. Remember that this is because we filled in the missing data with the mean of all ages, and it happens to be right where that peak is.\n",
    "\n",
    "Also, try plotting a bar chart (or a pie chart) showing the number of passengers who are male and female. To do this, group the dataset by sex and count the number of rows for each group. `num_passengers_by_sex` should be a `pd.Series` with  two indices: \"male\" and \"female\".\n",
    "\n",
    "Finally, try plotting a histogram of fares to see how asymmetric they are.\n",
    "\n",
    "**Note:** The plots are not autograded, only the data. Feel free to change them, experiment, and add more plots as you see fit. I had quite a lot of fun playing around with different aspects of the data. This is the reason to have EDA, after all :).\n",
    "\n",
    "**Note 2:** The variables should be really simple to set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ec5f395304a7be79124827f79c7d63ec",
     "grade": false,
     "grade_id": "cell-2c3caaa38c49514a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "all_ages = None\n",
    "num_passengers_by_sex = None\n",
    "all_fares = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "plt.hist(all_ages, bins = 20)\n",
    "plt.title(\"Distribution of ages\")\n",
    "plt.show()\n",
    "\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.pie(num_passengers_by_sex, labels = num_passengers_by_sex.index, autopct = \"%.2f%%\")\n",
    "plt.title(\"Passengers per sex\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(all_fares, bins = 20)\n",
    "plt.title(\"Distribution of fares\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "99e106190db24b727147d398e2014fdd",
     "grade": true,
     "grade_id": "cell-1e84086c6a0454d7",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_not_none(all_ages)\n",
    "assert_is_not_none(num_passengers_by_sex)\n",
    "assert_is_not_none(all_fares)\n",
    "\n",
    "assert_equal(len(all_ages), len(all_fares))\n",
    "assert_equal(num_passengers_by_sex.index.tolist(), [\"female\", \"male\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5. Explore correlations in the dataset (1 point)\n",
    "We can play a lot with single variables, groups, etc. But let's focus on correlations now.\n",
    "\n",
    "One of the first things we can do is check all correlations on all variables, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, there are some correlations but it seems nothing too interesting can be found.\n",
    "\n",
    "Let's now try some groupings. For example, what percentage of each gender survived? Recall that we calculated the total number of passengers for each gender in the previous exercise.\n",
    "\n",
    "Filter the `titanic_data` dataset to get only survived passengers and apply the same grouping and counting as you did in the previous exercise. You should get a series with \"male\" and \"female\" as the indices.\n",
    "\n",
    "If your answers are correct, the `print()` statements should run without errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6879abb15cfadda4f2b309d3c4932c25",
     "grade": false,
     "grade_id": "cell-7554388a9c07ce6f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "survived_passengers = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print(\"Survived men: {} / {}, {:.2f}%\".format(survived_passengers.male, num_passengers_by_sex.male, survived_passengers.male / num_passengers_by_sex.male * 100))\n",
    "print(\"Survived women: {} / {}, {:.2f}%\".format(survived_passengers.female, num_passengers_by_sex.female, survived_passengers.female / num_passengers_by_sex.female * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that a far greater proportion of women survived. This is really significant for two reasons: 1) the difference is really large (74% women vs. 19% men survived), 2) the total number of women on board is smaller.\n",
    "\n",
    "We can therefore conclude that women have been given advantage while evacuating from the ship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "916a87e6ebac9119d853b000127a150d",
     "grade": true,
     "grade_id": "cell-508e9ba1aadd8279",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_not_none(survived_passengers)\n",
    "assert_equal(num_passengers_by_sex.index.tolist(), [\"female\", \"male\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to look for more correlations if you wish.\n",
    "\n",
    "Let's now focus on something else: the distribution of ages broken down by class. As we already mentioned, passenger class can be used as a proxy for a person's wealth.\n",
    "\n",
    "Group the dataset by class and extract the ages for each group. Store this in the `ages_by_class` variable. It should be a `pd.Series` with `Class` as the index.\n",
    "\n",
    "Plot a histogram showing the three age distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "48fd907f7319418f61746d633edb516a",
     "grade": false,
     "grade_id": "cell-b0f18ef015029cc9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "ages_by_class = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: this is not an autograded cell. It's here only to help you \n",
    "# find out whether your answer and data format are correct\n",
    "assert_is_not_none(ages_by_class)\n",
    "assert_equal(ages_by_class.size().tolist(), [216, 184, 491])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for passenger_class, ages in ages_by_class:\n",
    "    plt.hist(ages, label = \"Class {}\".format(passenger_class), alpha = 0.7)\n",
    "plt.title(\"Distribution of passenger ages per class\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see something really interesting. It seems that first-class passengers are a little bit older than third-class passengers. But is this really true? We can't tell for sure. First of all, there are many more third-class passengers; and second, we can't be sure whether there's a significant difference or not.\n",
    "\n",
    "Fortunately, there's a rigorous statistical method to find out. Enter **hypothesis testing**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6. Perform hypothesis testing on age vs. class (1 point)\n",
    "First, let's store \"class 1\" and \"class 3\" passenger ages in their own variables, for easier work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_class_ages = ages_by_class.get_group(1)\n",
    "third_class_ages = ages_by_class.get_group(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform a hypothesis test, we'll need a hypothesis. Actually, a pair of hypotheses. The \"null hypothesis\", $H_0$ says that \"there's nothing interesting going on with the data\". The \"alternative hypothesis\", $H_1$ says the opposite.\n",
    "\n",
    "We want to prove whether or not the passenger class is correlated with the age. Therefore:\n",
    "* $H_0:$ Passenger class is not correlated with age. `first_class_ages` and `third_class_ages` are two samples from the same distribution.\n",
    "* $H_1:$ `first_class_ages` and `third_class_ages` come from two different distributions.\n",
    "\n",
    "Ideally, **we'd like to reject the null hypothesis**.\n",
    "\n",
    "Here's a quick explanation of the process: we'll perform a test. The exact details aren't important. We assume that $H_0$ is true, therefore **the differences between the two histograms occur simply by chance**. The test will return a $p$-value. It corresponds to the probability that we observe **as extreme or more extreme differences** between the two histograms if $H_0$ is really true.\n",
    "\n",
    "We have to agree on a \"threshold value\" of $p$. Usually that's 5% (0.05), but let's choose 1% in this case. What does this mean? If we reject $H_0$, there will still be 1% chance that we rejected it wrongly.\n",
    "\n",
    "**If $p\\le1\\%$, we will reject $H_0$**.\n",
    "\n",
    "To compare the two variables, it's easiest to perform what's called a **t-test**. It's already been imported for you. Call it like this: `test_result = ttest_ind(<first_variable>, <second_variable>, equal_var = False)`.\n",
    "\n",
    "**Note:** You can get additional information about the mechanics of statistical hypothesis testing on the Internet. Research more if you wish. You can also research what `equal_var = False` is and why we aren't allowed to assume equal variances in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c82e076dc2c993efb3542dad12387637",
     "grade": false,
     "grade_id": "cell-2fad87583bb70604",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "test_result = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print(test_result.pvalue)\n",
    "if test_result.pvalue <= 0.01:\n",
    "    print(\"The differences in age are significant. Reject H0.\")\n",
    "else:\n",
    "    print(\"There's not enough evidence to reject H0. Don't accept or reject anything else.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "71d34f381017f96f87caee725da0dcd3",
     "grade": true,
     "grade_id": "cell-7ce2e934e8d8ecb9",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_not_none(test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we can conclude that **the distributions of ages are significantly different at the 1% level**. Actually, they're so significantly different, that we might as well have chosen $1.10^{-17}\\%$ and still be correct.\n",
    "\n",
    "This means that ages are different for the different classes. How can we interpret this? Probably wealthier people are older. Younger people might not need, or might not be able to afford, a higher fare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7. Prepare the data for modelling: indicator variables (1 point)\n",
    "We're going to use `scikit-learn` to model the data. However, that's not so simple. We first need to preprocess the data a little.\n",
    "\n",
    "Most importantly, all variables should be numeric. `scikit-learn` doesn't know how to deal with text and categories.\n",
    "\n",
    "We need to convert `Sex` and `Embarked` to categories. There are many ways to do that.\n",
    "\n",
    "What's considered the best way is via the so-called \"indicator variables\". These are variables whose values are 0 or 1. For example, let's look at the \"Sex\" column. It has two possible values: \"male\" and \"female\". Each of these values will create a new column: `Sex_male` and `Sex_female`. If the passenger is male, he will have 1 in the `Sex_male` column, and so on. Similarly, with `Embarked`.\n",
    "\n",
    "There's a really easy way to do this in `pandas`: `pd.get_dummies(dataframe)`. Note that this returns another dataframe. Add the columns: `[\"Class\", \"Sex\", \"Embarked\"]` to the dataframe. Write the code and explore the newly created dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "579bcc593b53a883fd0f76395615a091",
     "grade": false,
     "grade_id": "cell-ce48a98dc2da3cce",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "titanic_data_for_modelling = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "titanic_data_for_modelling.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that we have more columns. We can also see that since `Sex` has only two possible values, the two columns `Sex_female` and `Sex_male` are just opposites of each other. We can safely remove one of them. However, this is not true for the `Class` and `Embarked` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3f3a74b69ef3afa7e884a482683a1822",
     "grade": false,
     "grade_id": "cell-eb71a6ae99067bb1",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "755132340ca2abe54bf54c8f217dabbd",
     "grade": true,
     "grade_id": "cell-cf11c03fee894a9c",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(titanic_data_for_modelling.shape, (891, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later, it will be really convenient to separate the explanatory variables from the target variable.\n",
    "\n",
    "We want to predict whether or not a person has survived. Therefore, `Survived` will be our target variable. All other variables will be our explanatory variables (also called features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data_features = titanic_data_for_modelling.drop(\"Survived\", axis = 1)\n",
    "titanic_data_target = titanic_data_for_modelling.Survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8. Prepare the data for modelling: normalization (1 point)\n",
    "In order for the model to perform better, we usually need to rescale the values for each numeric column. \n",
    "\n",
    "Why do we do this? It's related to algorithm stability and convergence. Generally, a machine learning algorithm will perform better if all values are in similar ranges.\n",
    "\n",
    "Do we always need it? No, but we usually do.\n",
    "\n",
    "There are many types of normalization. In this case, we're going to use a **min-max normalization**. The minimum value in the column will become 0, the maximum will become 1. All values in between will be scaled accordingly.\n",
    "\n",
    "`scikit-learn` has a very convenient [MinMaxScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler). You use it by simply instantiating it and passing the data:\n",
    "```python\n",
    "scaler = MinMaxScaler()\n",
    "titanic_data_features_scaled = scaler.fit_transform(titanic_data_features)\n",
    "```\n",
    "\n",
    "Note that `titanic_data_scaled` will be a 2D `numpy` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "da2b97f020a5c62730728fe988fefba8",
     "grade": false,
     "grade_id": "cell-15df658fa2716e19",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "titanic_data_scaled = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "183dbb5a7ba39784d3bdc9af8cdddcf2",
     "grade": true,
     "grade_id": "cell-8290e1e8c30f5922",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_not_none(titanic_data_features_scaled)\n",
    "assert_equal(titanic_data_features_scaled.shape, (891, 11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9. Split the data (0 points)\n",
    "When we want to evaluate a machine learning model, we usually hide some data from it. We train the model on most of the data, but when we test it afterwards, we pass the additional, hidden data. This is similar to how humans learn - a teacher won't give the exact answers to all students. If this was the case, the teacher cannot know whether a student really learned something, or just memorized all the answers.\n",
    "\n",
    "The function `train_test_split` from `scikit-learn` will perform the splitting for us. See the docs [here](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n",
    "\n",
    "We usually want $\\approx 70\\%$ of the data for training and the remaining $\\approx 30\\%$ for testing. It's very important that the data is shuffled. `train_test_split()` will do this by default.\n",
    "\n",
    "We'll pass the features and target variables and we'll get the different parts accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    titanic_data_features_scaled, titanic_data_target, train_size = 0.7, test_size = 0.3, random_state = 42)\n",
    "print(features_train.shape, features_test.shape, target_train.shape, target_test.shape, sep = \"\\r\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 10. Model the data (1 point)\n",
    "Let's model the data using logistic regression. That's very simple.\n",
    "\n",
    "First, create a logistic regression model (with no custom settings). Then, fit the model using the training features and training target.\n",
    "```python\n",
    "model = LogisticRegression()\n",
    "model.fit(???, ???)\n",
    "```\n",
    "\n",
    "If you wish, you can inspect the model coefficients and intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8944f6d44773d414c88c905183f67e8f",
     "grade": false,
     "grade_id": "cell-f0dd6abc403dec0a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "model = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bb65e5602e097608eaa7ee18a54a8fe7",
     "grade": true,
     "grade_id": "cell-4afb23030f0e02b5",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_not_none(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 11. Score the model (1 point)\n",
    "The default scoring metric for a classification model is **accuracy**. Use `model.score(???, ???)` to get an accuracy score for the model. This should be around 80%.\n",
    "\n",
    "**Note:** Remember to use `features_test` and `target_test`, not the training subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c0c14da725bb4e5b5411416a88aca49e",
     "grade": false,
     "grade_id": "cell-528f747f698aeadf",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "score = 0\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b85e5525d594ea45178885015d5939e5",
     "grade": true,
     "grade_id": "cell-0e64bb27e29b0292",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_greater(score, 0)\n",
    "assert_less_equal(score, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see that even though it might seem difficult at first, working with models is pretty easy.\n",
    "\n",
    "Feature preparation, train / test split, normalization, extraction of explanatory features vs. target, modelling, testing, and evaluating: these are all parts of the data modelling process. It's the basic idea of **machine learning**.\n",
    "\n",
    "We started from a dataset and we were able to explore, visualize, and model the data. After all this, we have several deliverables: notebook with our research, model (that we might upload somewhere - but that's outside the scope of this lab), (mostly) repeatable research. We have followed a careful and complete process to get to the final results.\n",
    "\n",
    "We can, of course, extend the study. But this is enough for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good luck on the exam! :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
