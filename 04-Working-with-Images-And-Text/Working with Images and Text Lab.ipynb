{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "from nose.tools import *\n",
    "\n",
    "import skimage.io\n",
    "# Write your imports here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Images and Text Lab\n",
    "## Working with unstructured data - images and text. Information retrieval, preprocessing, and feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical task which combines image processing, text processing, and some data analysis is performing optical character recognition (OCR) on an image.\n",
    "\n",
    "In this problem, we're going to do OCR on a scanned restaurant menu. The process is roughly as follows:\n",
    "* Preprocess the image: prepare for OCR\n",
    "* Perform OCR: get raw text from image\n",
    "* Process raw text: prepare for formatting into a table\n",
    "* Get a table (in this case, a really simple one)\n",
    "\n",
    "After this process, we'll get a table which will contain two columns: \"item name\" and \"price\". We can perform various operations on this table, e.g. text frequency analysis (e.g. \"What words are most frequent?\"), descriptive analytics (e.g. \"What's the most expensive item on the menu?\"), or more advanced stuff (\"What's the most expensive vegan dish on the menu?\"). The sky is the limit in what we can do (especially if we use many menus) but in this lab we'll focus mainly on data preparation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1. Read the images (1 point)\n",
    "We're going to read images from [this](http://menus.nypl.org/menus/26886/explore) menu. The restaurant's name is \"Park Avenue Cafe Townhouse\" and the menu is from 2001.\n",
    "\n",
    "As you can see, only the first and the second page contain meaningful information. These have been downloaded and provided for you in the folder `images` as `page1.jpg` and `page2.jpg`.\n",
    "\n",
    "**Note:** Please don't pay too much attention to the menu items listed on the right of the Web page. These have already been OCRed by a person :D and we're going to do this automatically (at least to some extent).\n",
    "\n",
    "Read the images as Python arrays first. Probably the easiest way to do this is by using `skimage` but you're free to do this in whatever way you like.\n",
    "\n",
    "Assign the image of the first page to the `page1` variable, and the image of the second page to the  `page2` variable. You can test to see if the images have been read correctly (for example, try showing them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "67cb7654a712905feb52bbe31ea607cd",
     "grade": false,
     "grade_id": "cell-d26bb91b09631fc2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "page1 = None\n",
    "page2 = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3a680b8a0e066cd6021a76503e77e5e3",
     "grade": true,
     "grade_id": "cell-eea727c06db030cb",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_not_none(page1)\n",
    "assert_is_not_none(page2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2. Convert the images to grayscale (1 point)\n",
    "We're going to need to extract the text. We don't need any color information so we might just discard it. We can do this in many different ways, including:\n",
    "* Take only one channel (e.g. the red one) and discard all others\n",
    "* Take the arithmetic mean of all channels\n",
    "* Convert to grayscale using gamma correction (adjusted for the sensitivity of human eyes)\n",
    "\n",
    "Although we commonly use the third approach, in this case either will do just fine. For the sake of the example, let's stick with the second one.\n",
    "\n",
    "Write a function that accepts an RGB image and returns a grayscale image. Each pixel in the RGB image must be the mean of E, G and B in the original image.\n",
    "\n",
    "**Example:** If an RGB pixel is (120, 24, 83), the grayscale pixel will be $\\frac{120 + 24 + 83}{3} = 75,66667 = 76$. \n",
    "\n",
    "Note that this process will reduce the number of dimensions of the image matrix from three to two. Also note that each number is rounded to the nearest integer. Make sure the output of your function is a 2D matrix of type `uint8`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ce866700cb75215e87d251a9a74d856b",
     "grade": false,
     "grade_id": "cell-1fbebfad88fcc6c7",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_grayscale(image):\n",
    "    \"\"\"\n",
    "    Converts the specified RGB image to grayscale, averaging over\n",
    "    the red, green, and blue channels\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "069bafc8c0f22d1e6975751fca0c9398",
     "grade": true,
     "grade_id": "cell-90b9c16adc333839",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "page1_gray = convert_to_grayscale(page1)\n",
    "page2_gray = convert_to_grayscale(page2)\n",
    "skimage.io.imshow_collection([page1_gray, page2_gray])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Problem 3. Crop the images (2 points)\n",
    "Since the images have quite a lot of border to them, we want to remove it in order to simplify the processing. Also, the fist page has a footer with some info about the restaurant. We don't need that so we can crop it away.\n",
    "\n",
    "Write a function which accepts an image and a cropping box, and returns only the pixels inside the cropping box. The box is specified using its top left corner and its bottom right corner. The two corners are given as tuples of coordinates. For example, `top_left = (500, 200), bottom_right = (700, 300)` will create a cropping box with corners: `top_left = (500, 200), top_right = (500, 300), bottom_left = (700, 200), bottom_right = (700, 300)`. The resulting image will have dimensions 200x100 px. Assume that all parameters will be correct, don't perform error handling.\n",
    "\n",
    "Be careful because the coordinates are confusing. To check you work, the function calls should contain only the text, without the border and footer of the images.\n",
    "\n",
    "Crop the images however you like. I find the sizes specified in the function call really convenient. Feel free to change them.\n",
    "\n",
    "**Note:** The left column in second page of the menu contains a dinner menu. It's a combination menu and it's not in our desired format. We're interested in prices of individual dishes, not dinners. In this case, it's easiest just to skip it.\n",
    "\n",
    "We might also say we're not interested in drinks and skip the entire second image in the menu but this one will allow us to create two datasets - one for food and one for wines.\n",
    "\n",
    "**Note 2:** It's evident that we need a little bit of rotation as well but the OCR will take care of that automatically. We don't have to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "bc8177925efea0bfe2f1858f15d10942",
     "grade": false,
     "grade_id": "cell-cc9b26e89149ec94",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def crop_image(image, top_left, bottom_right):\n",
    "    \"\"\"\n",
    "    Crops a grayscale image to the specified box. top_left and bottom_right are tuples\n",
    "    of two elements. The first element in each tuple specifies the x coordinate, \n",
    "    and the second element specifies the y coordinate.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page1_cropped = crop_image(page1_gray, (206, 124), (1700, 1245))\n",
    "page2_cropped = crop_image(page2_gray, (873, 138), (1622, 1343))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images):\n",
    "    for image in images:\n",
    "        plt.figure(figsize = (10, 8))\n",
    "        plt.imshow(image, cmap = \"gray\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dfeb3886e9bebde13847d57ba04c6feb",
     "grade": true,
     "grade_id": "cell-c4d986a9178ea9d6",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "show_images([page1_cropped, page2_cropped])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4. Split the first image (0 points)\n",
    "The first image contains two columns of text. Our OCR application will recognize that but it will be better to split the two columns and treat them as two different images, each with a single block of text.\n",
    "\n",
    "We can reuse our cropping function to do exactly that. Feel free to change the cropping boxes however you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page1_left_cropped = crop_image(page1_gray, (206, 124), (860, 1245))\n",
    "page1_right_cropped = crop_image(page1_gray, (1047, 124), (1700, 1245))\n",
    "show_images([page1_left_cropped, page1_right_cropped])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5. Concatenate the three images into one (1 point)\n",
    "In order to make text processing easier, it's better to have one image, not three. Concatenate all images vertically. You should get a long, narrow image. You'll need to resize them at the beginning, before concatenating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8fcba13012ef79f22b7354932f3538e0",
     "grade": false,
     "grade_id": "cell-2470674abcd69bca",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def resize_images(images):\n",
    "    \"\"\"\n",
    "    Resizes all images to have the same width\n",
    "    \"\"\"\n",
    "    max_width = max([image.shape[1] for image in images])\n",
    "    padded_images = [np.pad(image, ((0, 0), (0, max_width - image.shape[1])), mode = \"constant\", constant_values = 255) for image in images]\n",
    "    return padded_images\n",
    "\n",
    "def concatenate_images(images):\n",
    "    \"\"\"\n",
    "    Concatenates all images vertically (one below the other)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2c7a8eb7a751b9cc305daceaa86405ed",
     "grade": true,
     "grade_id": "cell-0598947a3abb3574",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "combined_image = concatenate_images([page1_left_cropped, page1_right_cropped, page2_cropped])\n",
    "show_images([combined_image])\n",
    "assert_true(combined_image.shape[0] >  combined_image.shape[1]) # Long, narrow image\n",
    "\n",
    "# Check dimensions\n",
    "assert_equal(combined_image.shape[0], page1_left_cropped.shape[0] + page1_right_cropped.shape[0] + page2_cropped.shape[0])\n",
    "assert_equal(combined_image.shape[1], max(page1_left_cropped.shape[1], page1_right_cropped.shape[1], page2_cropped.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6. Threshold the image (1 point)\n",
    "Apply thresholding to the image to remove the background and increase contrast. Wite a function that accepts an image and two thresholds: `low` and `high` (numbers in $[0; 255]$). For each pixel value $p$\n",
    "* If $p \\le$ `low`, replace it with 0\n",
    "* If `low`$\\lt p \\le$ `high`, leave it as it it\n",
    "* If `high`$\\lt p$, replace it with 255\n",
    "\n",
    "**Note:** The function should return a new image. It **must not** modify the original image!\n",
    "\n",
    "Apply the function to the combined image. You can experiment with the values of `low` and `high`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "22cb7180c1a962c5ccf6dc815d124f8f",
     "grade": false,
     "grade_id": "cell-39b2e4e92ba2cd53",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def threshold_image(image, low, high):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "759f51787c78f507e3e9d232b8da991a",
     "grade": true,
     "grade_id": "cell-01cc8857b82b76f8",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "cleaned_image = threshold_image(combined_image, low = 50, high = 200)\n",
    "show_images([cleaned_image])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the cleaned, thresholded and processed image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"output\"):\n",
    "    os.makedirs(\"output\")\n",
    "skimage.io.imsave(\"output/menu.jpg\", cleaned_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a nice image with high contrast. We can try applying OCR. The algorithms are entirely different topic but we can use already working ones.\n",
    "\n",
    "For this lab, we're going to use Google's **tesseract** library. You can install it from [here](https://github.com/UB-Mannheim/tesseract/wiki). Look for version 4. Installation is really simple - just follow the instructions. For Windows, just follow the installer. Add the installation folder to your `PATH` environment variable.\n",
    "\n",
    "Open a command prompt and write `tesseract -v`. If you see the version, everything has been installed correctly.\n",
    "\n",
    "Save the final image (execute the next cell). This will save it in `output/menu.jpg` (feel free to change the destination). Open a new terminal in the `output` folder and write:\n",
    "\n",
    "```tesseract [path to final image] [text file name]```\n",
    "\n",
    "Example:\n",
    "\n",
    "```tesseract menu.jpg menu```\n",
    "\n",
    "This will create a file `menu.txt` in the `output` folder. Be patient, as the process can take 1-2 minutes on some computers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the text file. Some editors (like the standard Notepad in Windows) don't recognize new lines properly. If you see a really long line, just try opening the text file in another editor, such as Notepad++.\n",
    "\n",
    "**Note:** Tesseract is really advanced. We could have skipped the entire preprocessing but: 1) it's useful, 2) it's fun, and 3) without processing, we get more reading errors. The library likes contrasting images with little or no background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7. Read the text file (1 point)\n",
    "Read the text file as a string. Be careful as there are some non-ASCII characters (look at \"ENTRÉES\" for example). Inspect it and correct any OCR errors. You can do this in any way you like. I prefer the manual way :D. I opened the output file and edited it directly.\n",
    "\n",
    "Also, I used a little bit of regular expression magic in Notepad to make sure that all menu items are on their own lines. This is especially imporant in the \"Shellfish by the piece\" and \"Side dishes\" sections.\n",
    "\n",
    "**Try to make the manually edited file as simple as possible to convert into tables.**\n",
    "\n",
    "Save the text content in the variable `menu_content`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b6aa63dbcc226ffefbc0965d2e7d7c95",
     "grade": false,
     "grade_id": "cell-240ea5ce0993e040",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "menu_content = \"\"\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print(menu_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3366b7e520e3f03a1b9110f061775679",
     "grade": true,
     "grade_id": "cell-565287667f5eb0bf",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_not_none(menu_content)\n",
    "assert_greater(len(menu_content), 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first few lines of my manually edited file are:\n",
    "```\n",
    "APPETIZERS\n",
    "Southern Fried Quail with Greens, Huckleberries, Pecans & Blue Cheese 14.00\n",
    "Park Avenue Cafe Chopped Salad Goat Feta Cheese, Niçoise Olives, Marinated\n",
    "[...]\n",
    "Black & White Bean Soup with Spicy Shrimp Quesadilla 11.50\n",
    "\n",
    "SHELLFISH BY THE PIECE\n",
    "Atlantic Oysters 2.25\n",
    "[...]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two tables. The first should contain meals, the second - drinks. In this lab, we'll onle create the meals table. Feel free to take the problem to the end and create the other tables. The process is exactly the same. The drinks table will not be autograded.\n",
    "\n",
    "How you create tables will depend on the way you created your text file. In my case, it was extremely simple.\n",
    "\n",
    "### Problem 8. Create the meals table (2 points)\n",
    "The table must have three columns: category (appetizers, entreés, side dishes, etc.); meal name and price. All meals are before \"Wine by the Glass\".\n",
    "\n",
    "Convert all category names to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2b639ca0650f63277ccbb0fa8bbda674",
     "grade": false,
     "grade_id": "cell-33188a6ffa37ba60",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "meals_string = menu_content[:menu_content.index(\"Wine by the Glass\")]\n",
    "def generate_meals_table(meals_string):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "13433ead567e6ca33a4147124156b8d2",
     "grade": true,
     "grade_id": "cell-cad2ea8c91da6d44",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "meals_table = generate_meals_table(meals_string)\n",
    "# There are 35 meals in total\n",
    "# The hidden tests check for their prices and categories\n",
    "assert_equal(meals_table.shape, (35, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9. Use your data (1 point)\n",
    "We've come a really long way. We started with an image, we did quite a lot of data exploration, image and text processing, and conversion to tables. Now we have a `pd.DataFrame`. This is considered structured data and our job is done. After that, we can proceed as we already know.\n",
    "\n",
    "To prove this, we'll just print some simple statistics.\n",
    "\n",
    "Calculate the number of items (total), number of categories, total items by category, and mean price by category. Assign these to the corresponding variables that are defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d8204553c417122506705130dd233663",
     "grade": false,
     "grade_id": "cell-dac355eadc25f45a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "num_items_total = None\n",
    "num_categories_total = None\n",
    "num_items_by_category = None\n",
    "mean_price_by_category = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2a71e795c1aad83481cc758e260310bb",
     "grade": true,
     "grade_id": "cell-08716e4048ef0714",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(num_items_total, 35)\n",
    "assert_equal(num_categories_total, 4)\n",
    "assert_equal(num_items_by_category.shape, (num_categories_total,))\n",
    "assert_equal(mean_price_by_category.shape, (num_categories_total,))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
